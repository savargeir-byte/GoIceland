#!/usr/bin/env python3
"""
Enrichar og uploadar bestu sta√∞ina √° √çslandi √≠ Firebase
Handpicked listi af helstu fer√∞amannast√∂√∞um
"""

import json
import time
import requests
from pathlib import Path
from typing import Dict, Optional

# Bestu sta√∞irnir √° √çslandi (handpicked)
TOP_PLACES = [
    "Gullfoss", "Geysir", "√ûingvellir", "Sk√≥gafoss", "Seljalandsfoss",
    "J√∂kuls√°rl√≥n", "Reynisfjara", "Dettifoss", "Go√∞afoss", "Hallgr√≠mskirkja",
    "Perlan", "Harpa", "Blue Lagoon", "Landmannalaugar", "√û√≥rsm√∂rk",
    "M√Ωvatn", "√Åsbyrgi", "Sn√¶fellsj√∂kull", "Dynjandi", "Kirkjufell",
    "V√≠ti", "Askja", "Hverir", "Svartifoss", "Aldeyjarfoss",
    "Hj√°lparfoss", "Glj√∫frab√∫i", "Fagradalsfjall", "Keri√∞", "Strokkur",
    "√ûingvallavatn", "Eyjafjallaj√∂kull", "Vatnaj√∂kull", "Langj√∂kull",
    "Hofsj√∂kull", "Hekla", "Katla", "Askja", "Her√∞ubrei√∞",
    "Hvannadalshnj√∫kur", "Esjan", "Krafla", "N√°mafjall", "Hverfjall",
    "Grj√≥tagj√°", "St√≥ragj√°", "Dimmuborgir", "Hlj√≥√∞aklettar", "Hengifoss",
    "Litlanesfoss", "Fja√∞r√°rglj√∫fur", "L√°trabjarg", "Dyrh√≥laey",
    "V√≠k √≠ M√Ωrdal", "H√∂fn", "Akureyri", "√çsafj√∂r√∞ur", "Egilssta√∞ir",
    "H√∫sav√≠k", "Sey√∞isfj√∂r√∞ur", "Vestmannaeyjar", "Grindav√≠k", "Borgarnes"
]

def load_places():
    """Hle√∞ur √∂llum st√∂√∞um"""
    with open('data/iceland_clean.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def find_place(places, search_name):
    """Finnur sta√∞ eftir nafni"""
    search_lower = search_name.lower()
    
    # Exact match first
    for p in places:
        if p.get('name', '').lower() == search_lower:
            return p
    
    # Partial match
    for p in places:
        name = p.get('name', '').lower()
        if search_lower in name or name in search_lower:
            return p
    
    return None

def get_wikipedia_info(place_name):
    """S√¶kir Wikipedia uppl√Ωsingar"""
    try:
        url = f"https://is.wikipedia.org/api/rest_v1/page/summary/{place_name.replace(' ', '_')}"
        response = requests.get(url, timeout=5, headers={'User-Agent': 'GoIceland/1.0'})
        
        if response.status_code == 200:
            data = response.json()
            return {
                'description': data.get('extract', ''),
                'thumbnail': data.get('thumbnail', {}).get('source'),
                'image': data.get('originalimage', {}).get('source'),
                'wikipedia_url': data.get('content_urls', {}).get('desktop', {}).get('page')
            }
        elif response.status_code == 404:
            # Try English
            url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{place_name.replace(' ', '_')}"
            response = requests.get(url, timeout=5, headers={'User-Agent': 'GoIceland/1.0'})
            if response.status_code == 200:
                data = response.json()
                return {
                    'description': data.get('extract', ''),
                    'thumbnail': data.get('thumbnail', {}).get('source'),
                    'image': data.get('originalimage', {}).get('source'),
                    'wikipedia_url': data.get('content_urls', {}).get('desktop', {}).get('page')
                }
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Wikipedia error: {e}")
    
    return {}

def enrich_place(place, place_name):
    """Enrichar sta√∞ me√∞ Wikipedia g√∂gnum"""
    wiki_info = get_wikipedia_info(place_name)
    
    enriched = {
        'id': place.get('id'),
        'name': place.get('name'),
        'type': place.get('category', 'attraction'),
        'category': place.get('category', 'attraction'),
        'lat': place.get('lat'),
        'lon': place.get('lng'),
        'latitude': place.get('lat'),
        'longitude': place.get('lng'),
        'country': 'IS',
        'description': {
            'short': wiki_info.get('description', '')[:200],
            'history': wiki_info.get('description', ''),
            'geology': '',
            'culture': ''
        },
        'media': {
            'images': [wiki_info.get('image')] if wiki_info.get('image') else [],
            'thumbnail': wiki_info.get('thumbnail'),
            'hero_image': wiki_info.get('image')
        },
        'rating': place.get('rating') or 4.5,
        'wikipedia_url': wiki_info.get('wikipedia_url'),
        'image': wiki_info.get('image'),
        'images': [wiki_info.get('image')] if wiki_info.get('image') else []
    }
    
    return enriched

def main():
    print('üåü ENRICHING TOP ICELAND PLACES')
    print('=' * 60)
    
    places = load_places()
    enriched_places = {}
    
    found = 0
    not_found = []
    
    for place_name in TOP_PLACES:
        print(f'\nüîç Searching: {place_name}')
        
        place = find_place(places, place_name)
        
        if place:
            found += 1
            print(f'   ‚úÖ Found: {place.get("name")} ({place.get("category")})')
            print(f'   üì° Getting Wikipedia data...')
            
            enriched = enrich_place(place, place_name)
            place_id = enriched['id']
            enriched_places[place_id] = enriched
            
            if enriched.get('image'):
                print(f'   üñºÔ∏è  Image found')
            
            time.sleep(0.5)  # Be nice to Wikipedia
        else:
            not_found.append(place_name)
            print(f'   ‚ùå Not found in database')
    
    print(f'\n\nüìä SUMMARY')
    print('=' * 60)
    print(f'‚úÖ Found and enriched: {found}')
    print(f'‚ùå Not found: {len(not_found)}')
    
    if not_found:
        print(f'\nMissing places:')
        for p in not_found[:10]:
            print(f'  - {p}')
    
    # Save enriched places
    output_file = Path('data/firestore_top_places.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(enriched_places, f, indent=2, ensure_ascii=False)
    
    print(f'\nüíæ Saved to: {output_file}')
    print(f'üì¶ Total places ready for Firebase: {len(enriched_places)}')

if __name__ == '__main__':
    main()
